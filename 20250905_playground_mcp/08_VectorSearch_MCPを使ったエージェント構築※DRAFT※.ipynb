{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "813ff527-faff-4b07-91ab-2bec5d0a17e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. MCPを使ったエージェント構築\n",
    "[DatabricksにおけるMCPを用いたエージェントの構築および評価](https://qiita.com/taka_yayoi/items/f2c7ad187ff3acbe0cc6)\n",
    "\n",
    "次のスニペットを実行して、MCPサーバーへの接続を検証します。このスニペットは、Unity Catalogツールを一覧表示し、その後ベクトル検索インデックスをクエリします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6377a3d0-5dd4-4177-9e2b-f55d8bbe59cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -U --quiet databricks-sdk databricks-langchain databricks-agents databricks-vectorsearch bs4==0.0.2 markdownify==0.14.1 pydantic==2.10.1 databricks-mcp mlflow mcp \"databricks-sdk[openai]\" databricks-agents\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1456fe15-fb72-4757-a4bc-8e61c4ec407b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U databricks-agents databricks-mcp databricks-vectorsearch mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09b8e462-1292-4b3d-a88b-e646565190e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acef7431-a3f7-40af-a74d-6f3f6b753491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "上記のスニペットを基に、ツールを使う基本的なシングルターンエージェントを定義できます。<br>\n",
    "後続のセクションでデプロイできるよう、エージェントのコードを mcp_agent.py という名前でローカルに保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54ad081a-b2f7-4756-bdd1-2c06ae5affa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from mcp.client.session import ClientSession\n",
    "from databricks_mcp import DatabricksOAuthClientProvider\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# ワークスペースへの認証を構成\n",
    "workspace_client = WorkspaceClient()\n",
    "workspace_hostname = workspace_client.config.host\n",
    "mcp_server_url = f\"{workspace_hostname}/api/2.0/mcp/vector-search/{catalog}/{schema}\"\n",
    "\n",
    "# 以下のスニペットは、Unity Catalog の関数 MCP サーバーを使用して Vector Search Index を公開します\n",
    "async def test_connect_to_server():\n",
    "    async with streamablehttp_client(\n",
    "        f\"{mcp_server_url}\", auth=DatabricksOAuthClientProvider(workspace_client)\n",
    "    ) as (read_stream, write_stream, _), ClientSession(\n",
    "        read_stream, write_stream\n",
    "    ) as session:\n",
    "        # MCP サーバーからツールを一覧取得し、呼び出す\n",
    "        await session.initialize()\n",
    "        tools = await session.list_tools()\n",
    "        toolnames = [t.name for t in tools.tools]\n",
    "        print(\n",
    "            f\"MCP サーバー {mcp_server_url} から検出されたツール: {toolnames}\"\n",
    "        )\n",
    "        result = await session.call_tool(\n",
    "            toolnames[0], {\"query\": \"Databricksとは何ですか？\"}\n",
    "        )\n",
    "        print(\n",
    "            f\"{toolnames[0]} ツールを呼び出し、結果を取得: {result.content}\"\n",
    "        )\n",
    "\n",
    "await test_connect_to_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb77431b-a33d-448e-a9c6-bfaadbd1930c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile mcp_agent.py\n",
    "\n",
    "import os\n",
    "from contextlib import asynccontextmanager\n",
    "import json\n",
    "import uuid\n",
    "import asyncio\n",
    "from typing import Any, Callable, List\n",
    "from pydantic import BaseModel\n",
    "import threading\n",
    "\n",
    "import mlflow\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import ResponsesAgentRequest, ResponsesAgentResponse\n",
    "\n",
    "from databricks_mcp import DatabricksOAuthClientProvider\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from mcp.client.session import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "# Databricksノートブック環境でのみnest_asyncioを適用\n",
    "if os.getenv('DATABRICKS_RUNTIME_VERSION') and 'ipykernel' in os.environ.get('_', ''):\n",
    "    # Databricksノートブック内\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    NOTEBOOK_ENV = True\n",
    "else:\n",
    "    # Model Servingやその他の環境\n",
    "    NOTEBOOK_ENV = False\n",
    "\n",
    "# 1) エンドポイント/プロファイルの設定\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "SYSTEM_PROMPT = \"あなたは有能なアシスタントです。\"\n",
    "workspace_client = WorkspaceClient()\n",
    "host = workspace_client.config.host\n",
    "\n",
    "# カタログ・データベース名を設定\n",
    "# catalog = \"takaakiyayoi_catalog\"\n",
    "# db = \"rag_chatbot_jpn\"\n",
    "import os\n",
    "catalog = os.environ.get(\"CATALOG\", \"default_catalog\")\n",
    "schema = os.environ.get(\"SCHEMA\", \"default_schema\")\n",
    "\n",
    "# 必要に応じてMCPサーバーURLを追加\n",
    "MCP_SERVER_URLS = [\n",
    "    f\"{host}/api/2.0/mcp/vector-search/{catalog}/{schema}\",\n",
    "]\n",
    "\n",
    "# 2) ResponsesAgent形式の\"message dict\"をChatCompletions形式に変換するヘルパー\n",
    "def _to_chat_messages(msg: dict[str, Any]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    ResponsesAgent形式のdictを1つ以上のChatCompletions互換dictに変換\n",
    "    \"\"\"\n",
    "    msg_type = msg.get(\"type\")\n",
    "    if msg_type == \"function_call\":\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": None,\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": msg[\"call_id\"],\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": msg[\"name\"],\n",
    "                            \"arguments\": msg[\"arguments\"],\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    elif msg_type == \"message\" and isinstance(msg[\"content\"], list):\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"assistant\" if msg[\"role\"] == \"assistant\" else msg[\"role\"],\n",
    "                \"content\": content[\"text\"],\n",
    "            }\n",
    "            for content in msg[\"content\"]\n",
    "        ]\n",
    "    elif msg_type == \"function_call_output\":\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": msg[\"output\"],\n",
    "                \"tool_call_id\": msg[\"tool_call_id\"],\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        # {\"role\": ..., \"content\": \"...\"}等のプレーンなdictのフォールバック\n",
    "        return [\n",
    "            {\n",
    "                k: v\n",
    "                for k, v in msg.items()\n",
    "                if k in (\"role\", \"content\", \"name\", \"tool_calls\", \"tool_call_id\")\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# 3) MCPセッションとツール呼び出しロジック\n",
    "@asynccontextmanager\n",
    "async def _mcp_session(server_url: str, ws: WorkspaceClient):\n",
    "    async with streamablehttp_client(\n",
    "        url=server_url, auth=DatabricksOAuthClientProvider(ws)\n",
    "    ) as (reader, writer, _):\n",
    "        async with ClientSession(reader, writer) as session:\n",
    "            await session.initialize()\n",
    "            yield session\n",
    "\n",
    "async def _list_tools_async(server_url: str, ws: WorkspaceClient):\n",
    "    async with _mcp_session(server_url, ws) as sess:\n",
    "        return await sess.list_tools()\n",
    "\n",
    "def _run_async_in_thread(coroutine):\n",
    "    \"\"\"\n",
    "    非同期コルーチンを専用スレッドのイベントループで実行（Model Serving向け）\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    exception = None\n",
    "    \n",
    "    def run_in_thread():\n",
    "        nonlocal result, exception\n",
    "        try:\n",
    "            # 新しいイベントループを作成\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            try:\n",
    "                result = loop.run_until_complete(coroutine)\n",
    "            finally:\n",
    "                loop.close()\n",
    "        except Exception as e:\n",
    "            exception = e\n",
    "    \n",
    "    # 別スレッドで実行\n",
    "    thread = threading.Thread(target=run_in_thread)\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "    \n",
    "    if exception:\n",
    "        raise exception\n",
    "    return result\n",
    "\n",
    "def _run_async_safely(coroutine):\n",
    "    \"\"\"\n",
    "    環境に応じて非同期コルーチンを安全に実行\n",
    "    \"\"\"\n",
    "    if NOTEBOOK_ENV:\n",
    "        # ノートブック: 既存イベントループを利用（nest_asyncio適用済み）\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            return asyncio.run(coroutine)\n",
    "        except RuntimeError:\n",
    "            # フォールバック: スレッド方式\n",
    "            return _run_async_in_thread(coroutine)\n",
    "    else:\n",
    "        # Model Serving: 常にスレッド方式\n",
    "        return _run_async_in_thread(coroutine)\n",
    "\n",
    "def _run_async_in_thread(coroutine):\n",
    "    \"\"\"\n",
    "    非同期コルーチンを専用スレッドのイベントループで実行（Model Serving向け）\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    exception = None\n",
    "    \n",
    "    def run_in_thread():\n",
    "        nonlocal result, exception\n",
    "        try:\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            try:\n",
    "                result = loop.run_until_complete(coroutine)\n",
    "            finally:\n",
    "                loop.close()\n",
    "        except Exception as e:\n",
    "            exception = e\n",
    "    \n",
    "    thread = threading.Thread(target=run_in_thread)\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "    \n",
    "    if exception:\n",
    "        raise exception\n",
    "    return result\n",
    "\n",
    "def _run_async_safely(coroutine):\n",
    "    \"\"\"\n",
    "    環境に応じて非同期コルーチンを安全に実行\n",
    "    \"\"\"\n",
    "    if NOTEBOOK_ENV:\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "            return asyncio.run(coroutine)\n",
    "        except RuntimeError:\n",
    "            return _run_async_in_thread(coroutine)\n",
    "    else:\n",
    "        return _run_async_in_thread(coroutine)\n",
    "\n",
    "def _list_tools(server_url: str, ws: WorkspaceClient):\n",
    "    # 安全な非同期実行\n",
    "    return _run_async_safely(_list_tools_async(server_url, ws))\n",
    "\n",
    "def _make_exec_fn(\n",
    "    server_url: str, tool_name: str, ws: WorkspaceClient\n",
    ") -> Callable[..., str]:\n",
    "    async def call_it_async(**kwargs):\n",
    "        async with _mcp_session(server_url, ws) as sess:\n",
    "            resp = await sess.call_tool(name=tool_name, arguments=kwargs)\n",
    "            return \"\".join([c.text for c in resp.content])\n",
    "    \n",
    "    def exec_fn(**kwargs):\n",
    "        # 安全な非同期実行\n",
    "        return _run_async_safely(call_it_async(**kwargs))\n",
    "\n",
    "    return exec_fn\n",
    "\n",
    "def _sanitize_tool_name(name: str, max_length: int = 64) -> str:\n",
    "    \"\"\"\n",
    "    Databricks要件に合わせてツール名をサニタイズ\n",
    "    - 英数字、アンダースコア、ハイフンのみ\n",
    "    - 最大64文字\n",
    "    - 正規表現 ^[a-zA-Z0-9_-]{1,64}$ に一致\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # 許可されていない文字をアンダースコアに置換\n",
    "    sanitized = re.sub(r'[^a-zA-Z0-9_-]', '_', name)\n",
    "    # 連続アンダースコアを1つに\n",
    "    sanitized = re.sub(r'_+', '_', sanitized)\n",
    "    # 先頭・末尾のアンダースコアを除去\n",
    "    sanitized = sanitized.strip('_')\n",
    "    # 空なら\"tool\"に\n",
    "    if not sanitized:\n",
    "        sanitized = \"tool\"\n",
    "    # 長さ制限\n",
    "    if len(sanitized) <= max_length:\n",
    "        result = sanitized\n",
    "    else:\n",
    "        # 長すぎる場合は分割して短縮\n",
    "        if \"_\" in sanitized:\n",
    "            parts = sanitized.split(\"_\")\n",
    "            last_part = parts[-1]\n",
    "            first_part = parts[0]\n",
    "            available_chars = max_length - len(last_part) - 1\n",
    "            if available_chars > 0 and len(first_part) <= available_chars:\n",
    "                result = f\"{first_part}_{last_part}\"\n",
    "            elif available_chars > 0:\n",
    "                first_part = first_part[:available_chars]\n",
    "                result = f\"{first_part}_{last_part}\"\n",
    "            else:\n",
    "                result = last_part[:max_length]\n",
    "        else:\n",
    "            result = sanitized[:max_length]\n",
    "    # 最終バリデーション\n",
    "    pattern = r'^[a-zA-Z0-9_-]{1,64}$'\n",
    "    if not re.match(pattern, result):\n",
    "        # 最後の手段: 英数字のみ\n",
    "        result = re.sub(r'[^a-zA-Z0-9]', '', result)\n",
    "        if not result:\n",
    "            result = \"tool\"\n",
    "        result = result[:max_length]\n",
    "    return result\n",
    "\n",
    "class ToolInfo(BaseModel):\n",
    "    name: str\n",
    "    spec: dict\n",
    "    exec_fn: Callable\n",
    "\n",
    "def _fetch_tool_infos(ws: WorkspaceClient, server_url: str) -> List[ToolInfo]:\n",
    "    print(f\"MCPサーバー {server_url} からツール一覧を取得\")\n",
    "    infos: List[ToolInfo] = []\n",
    "    try:\n",
    "        mcp_tools_result = _list_tools(server_url, ws)\n",
    "        mcp_tools = mcp_tools_result.tools\n",
    "        \n",
    "        for t in mcp_tools:\n",
    "            # ツール名をサニタイズ\n",
    "            original_name = t.name\n",
    "            sanitized_name = _sanitize_tool_name(t.name, 64)\n",
    "            # バリデーション\n",
    "            import re\n",
    "            pattern = r'^[a-zA-Z0-9_-]{1,64}$'\n",
    "            is_valid = re.match(pattern, sanitized_name)\n",
    "            print(f\"元名: '{original_name}'\")\n",
    "            print(f\"サニタイズ後: '{sanitized_name}' (長さ: {len(sanitized_name)}, valid: {bool(is_valid)})\")\n",
    "            if not is_valid:\n",
    "                print(f\"エラー: サニタイズ名がパターンに一致しません!\")\n",
    "                sanitized_name = \"vector_search_tool\"\n",
    "            schema = t.inputSchema.copy() if t.inputSchema else {}\n",
    "            if \"properties\" not in schema:\n",
    "                schema[\"properties\"] = {}\n",
    "            # 説明が長すぎる場合は切り詰め\n",
    "            description = t.description\n",
    "            if len(description) > 500:\n",
    "                description = description[:497] + \"...\"\n",
    "            spec = {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": sanitized_name,\n",
    "                    \"description\": description,\n",
    "                    \"parameters\": schema,\n",
    "                },\n",
    "            }\n",
    "            infos.append(\n",
    "                ToolInfo(\n",
    "                    name=original_name,  # 実行時は元名を使う\n",
    "                    spec=spec,\n",
    "                    exec_fn=_make_exec_fn(server_url, original_name, ws)\n",
    "                )\n",
    "            )\n",
    "        print(f\"{len(infos)}個のツールを正常にロード\")\n",
    "    except Exception as e:\n",
    "        print(f\"{server_url} からのツール取得エラー: {e}\")\n",
    "    return infos\n",
    "\n",
    "# 4) シングルターン型エージェントクラス\n",
    "class SingleTurnMCPAgent(ResponsesAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._tool_infos = None\n",
    "        self._tools_dict = None\n",
    "        self._workspace_client = None\n",
    "        \n",
    "    def _initialize_tools(self):\n",
    "        \"\"\"モデルロード時に一度だけツールを初期化\"\"\"\n",
    "        if self._tool_infos is None:\n",
    "            try:\n",
    "                self._workspace_client = WorkspaceClient()\n",
    "                self._tool_infos = [\n",
    "                    tool_info\n",
    "                    for mcp_server_url in MCP_SERVER_URLS\n",
    "                    for tool_info in _fetch_tool_infos(self._workspace_client, mcp_server_url)\n",
    "                ]\n",
    "                self._tools_dict = {tool_info.name: tool_info for tool_info in self._tool_infos}\n",
    "                print(f\"モデルロード時に{len(self._tool_infos)}個のツールを初期化\")\n",
    "            except Exception as e:\n",
    "                print(f\"警告: モデルロード時のツール初期化失敗: {e}\")\n",
    "                self._tool_infos = []\n",
    "                self._tools_dict = {}\n",
    "    \n",
    "    def _call_llm(self, history: List[dict], ws: WorkspaceClient, tool_infos):\n",
    "        \"\"\"\n",
    "        現在の履歴をLLMに送信し、生のレスポンスdictを返す\n",
    "        \"\"\"\n",
    "        client = ws.serving_endpoints.get_open_ai_client()\n",
    "        flat_msgs = []\n",
    "        for msg in history:\n",
    "            flat_msgs.extend(_to_chat_messages(msg))\n",
    "\n",
    "        # Databricksツール形式に変換\n",
    "        tools_param = None\n",
    "        if tool_infos:\n",
    "            tools_param = []\n",
    "            for ti in tool_infos:\n",
    "                function_spec = ti.spec[\"function\"]\n",
    "                tool_dict = {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": function_spec[\"name\"],\n",
    "                        \"description\": function_spec[\"description\"]\n",
    "                    }\n",
    "                }\n",
    "                # パラメータが存在し空でなければ追加\n",
    "                if function_spec.get(\"parameters\") and function_spec[\"parameters\"].get(\"properties\"):\n",
    "                    tool_dict[\"function\"][\"parameters\"] = function_spec[\"parameters\"]\n",
    "                else:\n",
    "                    # 空のパラメータ仕様\n",
    "                    tool_dict[\"function\"][\"parameters\"] = {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {}\n",
    "                    }\n",
    "                tools_param.append(tool_dict)\n",
    "            # ノートブック環境のみデバッグ出力\n",
    "            if NOTEBOOK_ENV:\n",
    "                print(f\"LLMに{len(tools_param)}個のツールを送信\")\n",
    "                for i, tool in enumerate(tools_param):\n",
    "                    print(f\"ツール {i}: {tool['function']['name']}\")\n",
    "                    import json\n",
    "                    print(f\"ツール構造: {json.dumps(tool, indent=2)}\")\n",
    "\n",
    "        # 複数アプローチで実行\n",
    "        try:\n",
    "            # まずtoolsパラメータ付きで実行\n",
    "            if tools_param:\n",
    "                return client.chat.completions.create(\n",
    "                    model=LLM_ENDPOINT_NAME,\n",
    "                    messages=flat_msgs,\n",
    "                    tools=tools_param,\n",
    "                )\n",
    "            else:\n",
    "                return client.chat.completions.create(\n",
    "                    model=LLM_ENDPOINT_NAME,\n",
    "                    messages=flat_msgs,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            if NOTEBOOK_ENV:\n",
    "                print(f\"最初の試行失敗: {e}\")\n",
    "                print(\"ツールなしでフォールバック...\")\n",
    "            # フォールバック: ツールなしで実行\n",
    "            return client.chat.completions.create(\n",
    "                model=LLM_ENDPOINT_NAME,\n",
    "                messages=flat_msgs,\n",
    "            )\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        # 未初期化ならツールを初期化\n",
    "        self._initialize_tools()\n",
    "        \n",
    "        ws = self._workspace_client or WorkspaceClient()\n",
    "\n",
    "        # 1) system+userで初期履歴を構築\n",
    "        history: List[dict] = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "        for inp in request.input:\n",
    "            history.append(inp.model_dump())\n",
    "\n",
    "        # 2) LLMを一度呼び出し\n",
    "        try:\n",
    "            # 事前ロード済みツールを利用\n",
    "            tool_infos = self._tool_infos\n",
    "            tools_dict = self._tools_dict\n",
    "            \n",
    "            if NOTEBOOK_ENV:\n",
    "                print(f\"事前ロード済みツール数: {len(tool_infos)}\")\n",
    "            \n",
    "            llm_resp = self._call_llm(history, ws, tool_infos)\n",
    "            raw_choice = llm_resp.choices[0].message.to_dict()\n",
    "            raw_choice[\"id\"] = uuid.uuid4().hex\n",
    "            history.append(raw_choice)\n",
    "\n",
    "            tool_calls = raw_choice.get(\"tool_calls\") or []\n",
    "            if tool_calls:\n",
    "                # （この例では単一ツールのみ対応）\n",
    "                fc = tool_calls[0]\n",
    "                requested_name = fc[\"function\"][\"name\"]\n",
    "                args = json.loads(fc[\"function\"][\"arguments\"])\n",
    "                # サニタイズ名から元名を検索\n",
    "                original_name = None\n",
    "                for tool_info in tool_infos:\n",
    "                    if tool_info.spec[\"function\"][\"name\"] == requested_name:\n",
    "                        original_name = tool_info.name\n",
    "                        break\n",
    "                if original_name and original_name in tools_dict:\n",
    "                    try:\n",
    "                        tool_info = tools_dict[original_name]\n",
    "                        result = tool_info.exec_fn(**args)\n",
    "                    except Exception as e:\n",
    "                        result = f\"{original_name}の呼び出しエラー: {e}\"\n",
    "                else:\n",
    "                    result = f\"ツール {requested_name} が見つかりません\"\n",
    "                # 4) \"tool\"出力を履歴に追加\n",
    "                history.append(\n",
    "                    {\n",
    "                        \"type\": \"function_call_output\",\n",
    "                        \"role\": \"tool\",\n",
    "                        \"id\": uuid.uuid4().hex,\n",
    "                        \"tool_call_id\": fc[\"id\"],\n",
    "                        \"output\": result,\n",
    "                    }\n",
    "                )\n",
    "                # 5) LLMを再度呼び出し、その返答を最終とする\n",
    "                followup = (\n",
    "                    self._call_llm(history, ws, tool_infos=[]).choices[0].message.to_dict()\n",
    "                )\n",
    "                followup[\"id\"] = uuid.uuid4().hex\n",
    "\n",
    "                assistant_text = followup.get(\"content\", \"\")\n",
    "                return ResponsesAgentResponse(\n",
    "                    output=[\n",
    "                        {\n",
    "                            \"id\": uuid.uuid4().hex,\n",
    "                            \"type\": \"message\",\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}],\n",
    "                        }\n",
    "                    ],\n",
    "                    custom_outputs=request.custom_inputs,\n",
    "                )\n",
    "\n",
    "            # 6) tool_callsがなければ元のassistant返答を返す\n",
    "            assistant_text = raw_choice.get(\"content\", \"\")\n",
    "            return ResponsesAgentResponse(\n",
    "                output=[\n",
    "                    {\n",
    "                        \"id\": uuid.uuid4().hex,\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": [{\"type\": \"output_text\", \"text\": assistant_text}],\n",
    "                    }\n",
    "                ],\n",
    "                custom_outputs=request.custom_inputs,\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            # エラー処理\n",
    "            error_message = f\"リクエスト処理中のエラー: {str(e)}\"\n",
    "            print(error_message)\n",
    "            return ResponsesAgentResponse(\n",
    "                output=[\n",
    "                    {\n",
    "                        \"id\": uuid.uuid4().hex,\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": [{\"type\": \"output_text\", \"text\": error_message}],\n",
    "                    }\n",
    "                ],\n",
    "                custom_outputs=request.custom_inputs,\n",
    "            )\n",
    "\n",
    "# MLflowモデルをセット\n",
    "mlflow.models.set_model(SingleTurnMCPAgent())\n",
    "\n",
    "# テスト実行\n",
    "try:\n",
    "    print(\"エージェントリクエスト作成中...\")\n",
    "    req = ResponsesAgentRequest(\n",
    "        input=[{\"role\": \"user\", \"content\": \"Databricksとは？\"}]\n",
    "    )\n",
    "    \n",
    "    print(\"予測実行中...\")\n",
    "    agent = SingleTurnMCPAgent()\n",
    "    resp = agent.predict(req)\n",
    "    \n",
    "    print(\"レスポンス:\")\n",
    "    for item in resp.output:\n",
    "        print(item)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"実行中のエラー: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "004a1246-4dd7-4296-9ec9-a038c3d8b68e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. MCPを使用してエージェントをデプロイする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0e990d5-b723-42cf-9f12-a17cf5315fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "MCPサーバーに接続するエージェントをデプロイする準備ができたら、[標準のエージェントデプロイメントプロセス](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/deploy-agent)を使用してください。<br>\n",
    "\n",
    "[エージェントがアクセスする必要があるすべてのリソースをログイン時に指定する](https://docs.databricks.com/aws/ja/generative-ai/agent-framework/log-agent#authentication-for-databricks-resources)ことを確認してください。<br>\n",
    "例えば、エージェントが以下のMCPサーバーURLを使用する場合：<br>\n",
    "`https://<your-workspace-hostname>/api/2.0/mcp/vector-search/prod/customer_support`<br>\n",
    "`https://<your-workspace-hostname>/api/2.0/mcp/vector-search/prod/billing`<br>\n",
    "`https://<your-workspace-hostname>/api/2.0/mcp/functions/prod/billing`<br>\n",
    "エージェントが必要とするすべてのベクトル検索インデックス、およびすべてのUnity Catalog関数をリソースとして指定する必要があります。<br>\n",
    "\n",
    "エージェントが必要とするすべてのベクトル検索インデックス、およびすべてのUnity Catalog関数をリソースとして指定する必要があります。<br>\n",
    "例えば、上記で定義されたエージェントをデプロイするには、エージェントコード定義をmcp_agent.pyに保存したと仮定して、次のスニペットを実行できます。<br>\n",
    "Pythonカーネルを再起動してimportするファイルを認識できるようにします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e33898-3f85-4134-a0be-d26c02e7c02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "876638a2-eeb7-4c92-94c4-6b0b59959cba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a49fa5-8837-4ae9-9ba4-d0a9ccd289d7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "環境変数を設定"
    }
   },
   "outputs": [],
   "source": [
    "# 環境変数を設定\n",
    "import os\n",
    "os.environ[\"CATALOG\"] = catalog\n",
    "os.environ[\"SCHEMA\"] = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a998adf-f3e1-4391-9eb5-d71b2ff233a1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "MCPエージェントをサービングエンドポイントにデプロイ"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks import agents\n",
    "import mlflow\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint, DatabricksVectorSearchIndex\n",
    "from mcp_agent import LLM_ENDPOINT_NAME\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "\n",
    "# mcp_agent.pyで定義されたエージェントをログ\n",
    "agent_script = \"mcp_agent.py\"\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    # --- エージェントコード内のMCP_SERVER_URLSを介して参照される場合、以下の行をアンコメントしてベクトル検索インデックスや追加のUC関数を指定 ---\n",
    "    DatabricksVectorSearchIndex(index_name=f\"{catalog}.{schema}.gold_feedbacks_index\"),\n",
    "    # DatabricksVectorSearchIndex(index_name=\"prod.billing.another_index\"),\n",
    "    # DatabricksFunction(f\"{catalog}.{schema}.get_store_product_inventory\"),\n",
    "    # DatabricksFunction(f\"{catalog}.{schema}.get_store_item_sales_ranking\"),\n",
    "    # DatabricksFunction(f\"{catalog}.{schema}.get_store_sales_ranking\"),\n",
    "]\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_model_info = mlflow.pyfunc.log_model(\n",
    "        name=\"mcp_agent\",\n",
    "        python_model=agent_script,\n",
    "        resources=resources,\n",
    "    )\n",
    "\n",
    "# TODO UCモデル名をここに指定\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.bricksmart_analysis_mcp_agent\"\n",
    "registered_model = mlflow.register_model(logged_model_info.model_uri, UC_MODEL_NAME)\n",
    "\n",
    "deployment_info = agents.deploy(\n",
    "    model_name=UC_MODEL_NAME,\n",
    "    model_version=registered_model.version,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b8af836-7125-4faf-b0c4-ab23153fe4fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "UCからモデル削除"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "for model_name in [f\"{catalog}.{schema}.bricksmart_analysis_mcp_agent\", f\"{catalog}.{schema}.feedback\"]:\n",
    "    try:\n",
    "        client.get_registered_model(model_name)\n",
    "        client.delete_registered_model(model_name)\n",
    "    except Exception:\n",
    "        pass  # モデルがなければ何もしない"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "08_VectorSearch_MCPを使ったエージェント構築※DRAFT※",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
