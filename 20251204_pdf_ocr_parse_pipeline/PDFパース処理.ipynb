{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e44e807e-1578-4b6d-8d2b-cac2aca3785d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "サーバレスコンピュートで実行してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dae3ba24-9e9d-4c0f-b140-3cbdbcaa58a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 0. 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69459118-5deb-4729-86f0-7090d31ddec6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# カタログ、スキーマ、ボリューム\n",
    "MY_CATALOG = \"komae_demo_v4\"        # 使用したいカタログ名に変更してください\n",
    "MY_SCHEMA = \"pdf_parse\"             # 使用したいスキーマ名に変更してください\n",
    "DATA_VOLUME = \"raw_data\"            # データ置き場\n",
    "CHECKPOINT_VOLUME = \"_checkpoints\"  # チェックポイント置き場"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b951e756-3e39-418f-8eb5-0e317aa28307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# カタログ、スキーマ、ボリューム作成\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {MY_CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {MY_CATALOG}.{MY_SCHEMA}\")\n",
    "\n",
    "spark.sql(f\"USE CATALOG {MY_CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA  {MY_SCHEMA}\")\n",
    "\n",
    "# データ用ボリューム作成\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {MY_CATALOG}.{MY_SCHEMA}.{DATA_VOLUME}\")\n",
    "\n",
    "# チェックポイント用ボリューム作成\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {MY_CATALOG}.{MY_SCHEMA}.{CHECKPOINT_VOLUME}\")\n",
    "\n",
    "print(f\"MY_CATALOG: {MY_CATALOG}\")\n",
    "print(f\"MY_SCHEMA: {MY_SCHEMA}\")\n",
    "print(f\"DATA_VOLUME: {DATA_VOLUME}\")\n",
    "print(f\"CHECKPOINT_VOLUME: {CHECKPOINT_VOLUME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2364fbba-1155-4d9c-8d28-d9e110ef6e0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# テーブルパスを指定\n",
    "BRONZE_TABLE = f\"{MY_CATALOG}.{MY_SCHEMA}.settlement_bronze\"\n",
    "SILVER_TABLE = f\"{MY_CATALOG}.{MY_SCHEMA}.settlement_silver\"\n",
    "GOLD_TABLE   = f\"{MY_CATALOG}.{MY_SCHEMA}.settlement_gold\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a1d4a99-2b3b-4ec4-a8bc-823723cde44e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b932498-572b-484a-9469-e8d818618b65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Auto LoaderでPDFをストリーミング読み込み\n",
    "bronze_stream_df = (\n",
    "    spark.readStream\n",
    "        .format(\"cloudFiles\")                                           # Auto Loader を使う指定\n",
    "        .option(\"cloudFiles.format\", \"binaryFile\")                      # バイナリファイル（PDFなど）として読み込む\n",
    "        .option(\"cloudFiles.includeExistingFiles\", \"true\")              # 初回に既存ファイルも取り込む\n",
    "        .option(\"cloudFiles.maxFilesPerTrigger\", \"50\")                  # 1マイクロバッチあたりの最大ファイル数\n",
    "        .load(f\"/Volumes/{MY_CATALOG}/{MY_SCHEMA}/{DATA_VOLUME}\")       # PDFファイル置き場（UCボリュームパス）\n",
    ")\n",
    "\n",
    "# 必要列だけ抽出（binaryFileソースのうち、path と content だけ使う）\n",
    "bronze_stream_df = bronze_stream_df.select(\"path\", \"content\")\n",
    "\n",
    "# ai_parse_document(content) でPDFバイナリをテキストに変換\n",
    "bronze_stream_df = bronze_stream_df.select(\"path\", F.expr(\"ai_parse_document(content)\").alias(\"content\"))\n",
    "\n",
    "# AvailableNow で「このジョブ起動時点までに到着済みの未処理PDF」をまとめて Bronze テーブルに書き込み\n",
    "bronze_query = (\n",
    "    bronze_stream_df.writeStream\n",
    "        .format(\"delta\")                                                           # Delta テーブルとして書き込む\n",
    "        .option(\n",
    "            \"checkpointLocation\",\n",
    "            f\"/Volumes/{MY_CATALOG}/{MY_SCHEMA}/{CHECKPOINT_VOLUME}/settlement_bronze\")   # Auto Loaderが「どのファイルをいつ処理したか」という状態を保存するチェックポイント\n",
    "        .outputMode(\"append\")                                                      # 新規ファイル分を追記\n",
    "        .trigger(availableNow=True)                                                # 今回の起動時点までの分だけを一気に処理するトリガー\n",
    "        .toTable(BRONZE_TABLE)                                                     # 書き込み先テーブル\n",
    ")\n",
    "\n",
    "# ストリーミング処理（AvailableNow のマイクロバッチ群）が完了するまで、このセルの実行をブロック\n",
    "bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b7f1596-ce18-47a0-abc0-baddf2b079bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Auto Loader適用しない場合、こちらのシンプルなコードでOKです\n",
    "# spark.sql(f\"\"\"\n",
    "# -- 決算書ボリュームのファイルの文字を抽出し、bronzeテーブルを作成\n",
    "# CREATE OR REPLACE TABLE {MY_CATALOG}.{MY_SCHEMA}.settlement_bronze AS\n",
    "# SELECT\n",
    "#   path,\n",
    "#   ai_parse_document(content) AS content\n",
    "# FROM\n",
    "#   READ_FILES(\n",
    "#     '/Volumes/{MY_CATALOG}/{MY_SCHEMA}/{MY_VOLUME}/pdf',\n",
    "#     format => 'binaryFile'\n",
    "#   );\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "040b8516-8bea-4474-b04c-886a98cac862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67fb48bf-cb35-45e1-b20e-420e9fe546a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    '貴方はテキスト整理のプロフェッショナルです。決算についてJSON形式でまとめてください。parse_jsonできるように余計な文字列は入れないでください。'\n",
    "    'それぞれのセグメントごとに売上高、営業利益、対前年同期売上増減率、概況状況をまとめて一つのテキストに整形してください。'\n",
    "    'Keyはそれぞれ\\\"セグメント\\\"、\\\"売上高\\\"、\\\"営業利益\\\"、\\\"対前年同期売上増減率\\\"、\\\"概況\\\"でお願いします。'\n",
    "    '[で始まり、]で終わるJSONで返してください。```json```という文字列は抜いてください。'\n",
    ")\n",
    "\n",
    "# 1回目だけテーブル定義を作成\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SILVER_TABLE} (\n",
    "  path    STRING,\n",
    "  summary STRING\n",
    ")\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# Bronze にある path のうち、まだ Silver に無いものだけ LLM 要約して追加\n",
    "spark.sql(f\"\"\"\n",
    "MERGE INTO {SILVER_TABLE} s\n",
    "USING (\n",
    "  SELECT\n",
    "    path,\n",
    "    ai_query(\n",
    "      'databricks-claude-sonnet-4',\n",
    "      '{prompt}' || content\n",
    "    ) AS summary\n",
    "  FROM {BRONZE_TABLE}\n",
    ") b\n",
    "ON s.path = b.path\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (path, summary) VALUES (b.path, b.summary)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47bcf9cc-9a6a-4d4b-aca2-1e9e5f9f4e65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fbfabc9-f552-4f9f-89f4-e5813338a257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1回目だけテーブル定義を作成（なければ作る）\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {GOLD_TABLE} (\n",
    "  id          STRING,\n",
    "  company     STRING,\n",
    "  Industry    STRING,\n",
    "  segment     STRING,\n",
    "  Sales       DOUBLE,\n",
    "  profit      DOUBLE,\n",
    "  yoy_change  STRING,\n",
    "  summary     STRING\n",
    ")\n",
    "USING delta\n",
    "\"\"\")\n",
    "\n",
    "# まだGoldに入っていない (path, segment) だけを抽出してINSERT\n",
    "spark.sql(f\"\"\"\n",
    "INSERT INTO {GOLD_TABLE}\n",
    "SELECT\n",
    "  uuid() AS id,\n",
    "  regexp_extract(\n",
    "    split(s.path, '/')[size(split(s.path, '/'))-1],\n",
    "    '^(.*)\\.',\n",
    "    1\n",
    "  ) AS company,\n",
    "  split(s.path, '/')[5] AS Industry,\n",
    "  exploded_case.`セグメント` AS segment,\n",
    "  try_cast(\n",
    "    regexp_replace(\n",
    "      regexp_extract(exploded_case.`売上高`, '([0-9,.]+)', 1),\n",
    "      ',',\n",
    "      ''\n",
    "    ) AS DOUBLE\n",
    "  ) * CASE WHEN exploded_case.`売上高` LIKE '%億%' THEN 100 ELSE 1 END AS Sales,\n",
    "  try_cast(\n",
    "    regexp_replace(\n",
    "      regexp_extract(exploded_case.`営業利益`, '([0-9,.]+)', 1),\n",
    "      ',',\n",
    "      ''\n",
    "    ) AS DOUBLE\n",
    "  ) * CASE WHEN exploded_case.`営業利益` LIKE '%億%' THEN 100 ELSE 1 END AS profit,\n",
    "  exploded_case.`対前年同期売上増減率` AS yoy_change,\n",
    "  exploded_case.`概況` AS summary\n",
    "FROM (\n",
    "  SELECT\n",
    "    path,\n",
    "    EXPLODE(\n",
    "      from_json(\n",
    "        summary,\n",
    "        'ARRAY<STRUCT<`セグメント`:STRING,`売上高`:STRING,`営業利益`:STRING,`対前年同期売上増減率`:STRING,`概況`:STRING>>'\n",
    "      )\n",
    "    ) AS exploded_case\n",
    "  FROM {SILVER_TABLE}\n",
    ") s\n",
    "LEFT ANTI JOIN {GOLD_TABLE} g\n",
    "ON\n",
    "  g.company = regexp_extract(\n",
    "    split(s.path, '/')[size(split(s.path, '/'))-1],\n",
    "    '^(.*)\\.',\n",
    "    1\n",
    "  )\n",
    "  AND g.segment = s.exploded_case.`セグメント`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b3ee621-d165-43ba-945b-5451a67c6b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. 初回実行のみ。以降は再実行不要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9ec4f3-a407-4c65-a5af-e5811705ec6d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "主キー設定"
    }
   },
   "outputs": [],
   "source": [
    "# 変数定義\n",
    "TABLE_PATH = f'{MY_CATALOG}.{MY_SCHEMA}.settlement_gold'                 # テーブルパス\n",
    "PK_CONSTRAINT_NAME = f'pk_settlement_gold'                               # 主キー\n",
    "\n",
    "# NOT NULL制約の追加\n",
    "columns_to_set_not_null = [\n",
    "    'id']\n",
    "\n",
    "for column in columns_to_set_not_null:\n",
    "    spark.sql(f\"\"\"\n",
    "    ALTER TABLE {TABLE_PATH}\n",
    "    ALTER COLUMN {column} SET NOT NULL;\n",
    "    \"\"\")\n",
    "\n",
    "# 主キー設定\n",
    "spark.sql(f'''\n",
    "ALTER TABLE {TABLE_PATH} DROP CONSTRAINT IF EXISTS {PK_CONSTRAINT_NAME};\n",
    "''')\n",
    "\n",
    "spark.sql(f'''\n",
    "ALTER TABLE {TABLE_PATH}\n",
    "ADD CONSTRAINT {PK_CONSTRAINT_NAME} PRIMARY KEY (id);\n",
    "''')\n",
    "\n",
    "# # チェック\n",
    "# display(\n",
    "#     spark.sql(f'''\n",
    "#     DESCRIBE EXTENDED {TABLE_PATH}\n",
    "#     '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e72c27ce-15f1-4935-958f-1925a57c1613",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "コメント追加"
    }
   },
   "outputs": [],
   "source": [
    "# テーブル名\n",
    "table_name = f'{MY_CATALOG}.{MY_SCHEMA}.settlement_gold'\n",
    "\n",
    "# テーブルコメント\n",
    "table_comment = \"\"\"\n",
    "テーブル名: settlement_gold / 決算書（ゴールド）\n",
    "説明: 決算書PDFから抽出した各セグメントの売上高・営業利益・対前年同期比などを構造化した分析用テーブル\n",
    "\"\"\"\n",
    "spark.sql(f'COMMENT ON TABLE {table_name} IS \"{table_comment}\"')\n",
    "\n",
    "# カラムコメント\n",
    "column_comments = {\n",
    "    \"id\": \"UUIDで採番した一意のID\",\n",
    "    \"company\": \"決算書ファイル名から抽出した企業名\",\n",
    "    \"Industry\": \"パスから抽出した業種（業界）\",\n",
    "    \"segment\": \"決算書内のセグメント名\",\n",
    "    \"Sales\": \"セグメントの売上高（数値、単位調整済み）\",\n",
    "    \"profit\": \"セグメントの営業利益（数値、単位調整済み）\",\n",
    "    \"yoy_change\": \"対前年同期売上増減率（文字列）\",\n",
    "    \"summary\": \"セグメントの概況説明テキスト\"\n",
    "}\n",
    "\n",
    "for column, comment in column_comments.items():\n",
    "    # シングルクォートをエスケープ\n",
    "    escaped_comment = comment.replace(\"'\", \"\\\\'\")\n",
    "    sql_query = f\"ALTER TABLE {table_name} ALTER COLUMN {column} COMMENT '{escaped_comment}'\"\n",
    "    spark.sql(sql_query)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3188636616085796,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "PDFパース処理",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
